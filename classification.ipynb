{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1: Importar as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os caminhos\n",
    "data_folder = \"nuvem_de_pontos/\"\n",
    "DATANAME = \"3DML_urban_point_cloud.xyz\"\n",
    "\n",
    "# Carregar os dados\n",
    "pcd = pd.read_csv(data_folder + DATANAME, delimiter=' ')\n",
    "pcd.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar os dados\n",
    "labels = pcd['Classification']\n",
    "features = pcd[['X', 'Y', 'Z', 'R', 'G', 'B']]\n",
    "features_scaled = MinMaxScaler().fit_transform(features)\n",
    "\n",
    "# Dividir os dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.4)\n",
    "\n",
    "# Treinar o classificador\n",
    "rf_classifier = RandomForestClassifier(n_estimators=10)\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o modelo\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "print(classification_report(y_test, rf_predictions, target_names=['ground', 'vegetation', 'buildings']))\n",
    "\n",
    "# Salvar o modelo treinado\n",
    "model_filename = data_folder + \"treinado\\\\aprendizado.pkl\"\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(rf_classifier, model_file)\n",
    "\n",
    "print(f\"Modelo salvo em: {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o caminho para o modelo salvo e para os novos dados\n",
    "path = \"treinado\\\\aprendizado.pkl\"\n",
    "model_path = data_folder + path\n",
    "data = \"TESTE.xyz\"\n",
    "new_data_path = data_folder + data\n",
    "\n",
    "# Carregar o modelo treinado\n",
    "with open(model_path, 'rb') as model_file:\n",
    "    rf_classifier = pickle.load(model_file)\n",
    "\n",
    "# Carregar e preparar a nova nuvem de pontos\n",
    "# Lê o arquivo ignorando a primeira linha (cabeçalho comentado)\n",
    "new_pcd = pd.read_csv(new_data_path, delimiter=' ', header=None, skiprows=1)\n",
    "\n",
    "# Define os nomes das colunas conforme o cabeçalho informado\n",
    "columns = ['X', 'Y', 'Z', 'R', 'G', 'B', 'Intensity', 'Return_Number', 'Number_Of_Returns', 'Scan_Direction_Flag', 'Classification', 'Scan_Angle', 'User_Data', 'Point_Source_ID', 'Gps_Time', 'Near_Infrared']\n",
    "new_pcd.columns = columns\n",
    "\n",
    "# Selecionar somente as colunas relevantes para a classificação\n",
    "new_features = new_pcd[['X', 'Y', 'Z', 'R', 'G', 'B']]\n",
    "new_features_scaled = MinMaxScaler().fit_transform(new_features)\n",
    "\n",
    "# Classificar a nova nuvem de pontos\n",
    "new_predictions = rf_classifier.predict(new_features_scaled)\n",
    "\n",
    "# Adicionar as previsões ao DataFrame e salvar os resultados\n",
    "new_pcd['Classification'] = new_predictions\n",
    "output_path = \"classificado.xyz\"\n",
    "new_pcd.to_csv(data_folder + output_path, index=False, sep=' ')\n",
    "\n",
    "print(f\"Nuvem de pontos classificada salva em: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizar a Nuvem de Pontos\n",
    "# Carregar os dados da nuvem de pontos\n",
    "data = np.loadtxt(data_folder + DATANAME, skiprows=1, delimiter=\" \")\n",
    "\n",
    "\n",
    "# Extrair as coordenadas XYZ\n",
    "points = data[:, 0:3]\n",
    "\n",
    "# Extrair as cores RGB (opcional)\n",
    "colors = data[:, 3:6] / 255.0\n",
    "\n",
    "# Criar um ponto nuvem Open3D\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "# Colocando cores originais\n",
    "if colors is not None:\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# Visualizar a nuvem de pontos\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizar a Nuvem de Pontos Classificada\n",
    "# Extrair as classificações\n",
    "classifications = data[:, 13]\n",
    "\n",
    "# Cores para cada classe\n",
    "colors = {\n",
    "    \"1.0\": [0.1, 0.8, 0.1],  # Terreno (verde)\n",
    "    \"2.0\": [0.0, 0.5, 0.0],  # Vegetação (verde escuro)\n",
    "    \"3.0\": [0.8, 0.6, 0.2],  # Construção (marrom)\n",
    "}\n",
    "\n",
    "# Mapear as classificações para cores\n",
    "point_colors = [colors[str(c)] for c in classifications]\n",
    "\n",
    "# Criar um ponto nuvem Open3D\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(point_colors)\n",
    "\n",
    "# Visualizar a nuvem de pontos Classificada\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
